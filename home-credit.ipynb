{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T12:40:17.381308Z","iopub.execute_input":"2024-04-18T12:40:17.381748Z","iopub.status.idle":"2024-04-18T12:40:18.699010Z","shell.execute_reply.started":"2024-04-18T12:40:17.381709Z","shell.execute_reply":"2024-04-18T12:40:18.697312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score ","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:18.701536Z","iopub.execute_input":"2024-04-18T12:40:18.702104Z","iopub.status.idle":"2024-04-18T12:40:21.869693Z","shell.execute_reply.started":"2024-04-18T12:40:18.702068Z","shell.execute_reply":"2024-04-18T12:40:21.868398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/home-credit-credit-risk-model-stability/\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:21.871138Z","iopub.execute_input":"2024-04-18T12:40:21.871694Z","iopub.status.idle":"2024-04-18T12:40:21.876876Z","shell.execute_reply.started":"2024-04-18T12:40:21.871649Z","shell.execute_reply":"2024-04-18T12:40:21.875756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n    for col in df.columns:\n        if col[-1] in (\"P\", \"A\"):\n            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n    return df\n\n\ndef convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n    for col in df.columns:  \n        if df[col].dtype.name in ['object', 'string']:\n            df[col] = df[col].astype(\"string\").astype('category')\n            current_categories = df[col].cat.categories\n            new_categories = current_categories.to_list() + [\"Unknown\"]\n            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n            df[col] = df[col].astype(new_dtype)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:21.879931Z","iopub.execute_input":"2024-04-18T12:40:21.880272Z","iopub.status.idle":"2024-04-18T12:40:21.893057Z","shell.execute_reply.started":"2024-04-18T12:40:21.880244Z","shell.execute_reply":"2024-04-18T12:40:21.891880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**train dataset**","metadata":{}},{"cell_type":"code","source":"# train base table\ntbt = pl.read_csv(DATA_PATH + \"csv_files/train/train_base.csv\")\n\n# train credit bureau <take a_2_0 as example>\ntcba20 = pl.read_csv(DATA_PATH + \"csv_files/train/train_credit_bureau_a_2_1.csv\").pipe(set_table_dtypes)\n\n# train static 0 0\nts00 = pl.read_csv(DATA_PATH + \"csv_files/train/train_static_0_0.csv\").pipe(set_table_dtypes)\n\n# train static 0 1\nts01 = pl.read_csv(DATA_PATH  + \"csv_files/train/train_static_0_1.csv\").pipe(set_table_dtypes)\n\n# train static cb 0\ntscb0 = pl.read_csv(DATA_PATH + \"csv_files/train/train_static_cb_0.csv\").pipe(set_table_dtypes)\n\n# train static person 1\ntsp1 = pl.read_csv(DATA_PATH + \"csv_files/train/train_person_1.csv\").pipe(set_table_dtypes)   \n\n# train credit bureau b 2\ntcbb2 = pl.read_csv(DATA_PATH + \"csv_files/train/train_credit_bureau_b_2.csv\").pipe(set_table_dtypes)\n\t\n\n# train dataset\n# train static\ntr_st = pl.concat([ts00, ts01], how=\"vertical_relaxed\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:21.895559Z","iopub.execute_input":"2024-04-18T12:40:21.896046Z","iopub.status.idle":"2024-04-18T12:40:22.256818Z","shell.execute_reply.started":"2024-04-18T12:40:21.896006Z","shell.execute_reply":"2024-04-18T12:40:22.255685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**test** **dataset**","metadata":{}},{"cell_type":"code","source":"# test base table\ntestbt = pl.read_csv(DATA_PATH + \"csv_files/test/test_base.csv\")\n\n# test static 0 x\ntests00 = pl.read_csv(DATA_PATH + \"csv_files/test/test_static_0_0.csv\").pipe(set_table_dtypes)\n\n# test static 0 x\ntests01 = pl.read_csv(DATA_PATH + \"csv_files/test/test_static_0_1.csv\").pipe(set_table_dtypes)\n\n# test static 0 x\ntests02 = pl.read_csv(DATA_PATH + \"csv_files/test/test_static_0_2.csv\").pipe(set_table_dtypes)\n\n# test static cb 0\ntestscb0 = pl.read_csv(DATA_PATH + \"csv_files/test/test_static_cb_0.csv\").pipe(set_table_dtypes)\n\n# test static person 1\ntestsp1 = pl.read_csv(DATA_PATH + \"csv_files/test/test_person_1.csv\").pipe(set_table_dtypes)   \n\n# test credit bureau b 2\ntestcbb2 = pl.read_csv(DATA_PATH + \"csv_files/test/test_credit_bureau_b_2.csv\").pipe(set_table_dtypes)\n\t\n    \n    \n# test static\ntest_st = pl.concat([tests00, tests01, tests02], how=\"vertical_relaxed\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:51.213752Z","iopub.execute_input":"2024-04-18T12:40:51.214160Z","iopub.status.idle":"2024-04-18T12:40:51.229024Z","shell.execute_reply.started":"2024-04-18T12:40:51.214126Z","shell.execute_reply":"2024-04-18T12:40:51.227594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Menyala abangkuuuu ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥**","metadata":{}},{"cell_type":"code","source":"tsp1_feats_1 = tsp1.group_by(\"case_id\").agg(\n    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n)\n\ntsp1_feats_2 = tsp1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(pl.col(\"num_group1\")==0).drop(\"num_group1\").rename({\"housetype_905L\" : \"personal_housetype\"})\n\n\n# Here we have num_goup1 and num_group2, so we need to aggregate again.\ntcb_b_2_feats = tcbb2.group_by(\"case_id\").agg(\n    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n)\n\nselected_static_cols = []\nfor col in tr_st.columns:\n    if col[-1] in (\"A\", \"M\"):\n        selected_static_cols.append(col)\n        \nselected_static_cb_cols = []\nfor col in tscb0.columns:\n    if col[-1] in (\"A\", \"M\"):\n        selected_static_cb_cols.append(col)\n\ndata_train = tbt.join(\n    tr_st.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n).join(\n    tscb0.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n).join(tsp1_feats_1, how=\"left\", on=\"case_id\"\n      ).join(tsp1_feats_2, how=\"left\", on=\"case_id\"\n            ).join(tcb_b_2_feats, how=\"left\", on=\"case_id\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:51.365048Z","iopub.execute_input":"2024-04-18T12:40:51.365386Z","iopub.status.idle":"2024-04-18T12:40:56.095600Z","shell.execute_reply.started":"2024-04-18T12:40:51.365359Z","shell.execute_reply":"2024-04-18T12:40:56.094293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testp1_feats_1 = testsp1.group_by(\"case_id\").agg(\n    pl.col(\"mainoccupationinc_384A\").max().alias(\"mainoccupationinc_384A_max\"),\n    (pl.col(\"incometype_1044T\") == \"SELFEMPLOYED\").max().alias(\"mainoccupationinc_384A_any_selfemployed\")\n)\n\ntestp1_feats_2 = testsp1.select([\"case_id\", \"num_group1\", \"housetype_905L\"]).filter(pl.col(\"num_group1\")==0).drop(\"num_group1\").rename({\"housetype_905L\" : \"personal_housetype\"})\n\n\n# Here we have num_goup1 and num_group2, so we need to aggregate again.\ntestcb_b_2_feats = testcbb2.group_by(\"case_id\").agg(\n    pl.col(\"pmts_pmtsoverdue_635A\").max().alias(\"pmts_pmtsoverdue_635A_max\"),\n    (pl.col(\"pmts_dpdvalue_108P\") > 31).max().alias(\"pmts_dpdvalue_108P_over31\")\n)\n\n\ndata_test = testbt.join(\n    test_st.select([\"case_id\"]+selected_static_cols), how=\"left\", on=\"case_id\"\n).join(\n    testscb0.select([\"case_id\"]+selected_static_cb_cols), how=\"left\", on=\"case_id\"\n).join(testp1_feats_1, how=\"left\", on=\"case_id\"\n      ).join(testp1_feats_2, how=\"left\", on=\"case_id\"\n            ).join(testcb_b_2_feats, how=\"left\", on=\"case_id\")\n\nprint(data_test.columns)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:56.096730Z","iopub.execute_input":"2024-04-18T12:40:56.097064Z","iopub.status.idle":"2024-04-18T12:40:56.121548Z","shell.execute_reply.started":"2024-04-18T12:40:56.097037Z","shell.execute_reply":"2024-04-18T12:40:56.120116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data_test.columns)\nprint(\"###############\")\nprint(data_train.columns)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:56.123495Z","iopub.execute_input":"2024-04-18T12:40:56.123950Z","iopub.status.idle":"2024-04-18T12:40:56.130992Z","shell.execute_reply.started":"2024-04-18T12:40:56.123912Z","shell.execute_reply":"2024-04-18T12:40:56.129518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"case_ids = data_train[\"case_id\"].unique().shuffle(seed=1)\ncase_ids_train, case_ids_test = train_test_split(case_ids, train_size=0.6, random_state=1)\ncase_ids_valid, case_ids_test = train_test_split(case_ids_test, train_size=0.5, random_state=1)\ncols_pred = []\n\nfor col in data_train.columns:\n    if col[-1].isupper() and col[:-1].islower():\n        cols_pred.append(col)\nprint(cols_pred)\n\ndef from_polars_to_pandas(case_ids: pl.DataFrame) -> pl.DataFrame:\n    return (\n        data_train.filter(pl.col(\"case_id\").is_in(case_ids))[[\"case_id\", \"WEEK_NUM\", \"target\"]].to_pandas(),\n        data_train.filter(pl.col(\"case_id\").is_in(case_ids))[cols_pred].to_pandas(),\n        data_train.filter(pl.col(\"case_id\").is_in(case_ids))[\"target\"].to_pandas()\n    )\n\nbase_train, X_train, y_train = from_polars_to_pandas(case_ids_train)\nbase_valid, X_valid, y_valid = from_polars_to_pandas(case_ids_valid)\nbase_test, X_test, y_test = from_polars_to_pandas(case_ids_test)\n\nfor df in [X_train, X_valid, X_test]:\n    df = convert_strings(df)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:40:56.132902Z","iopub.execute_input":"2024-04-18T12:40:56.133494Z","iopub.status.idle":"2024-04-18T12:41:10.797904Z","shell.execute_reply.started":"2024-04-18T12:40:56.133454Z","shell.execute_reply":"2024-04-18T12:41:10.791696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Train: {X_train.shape}\")\nprint(f\"Valid: {X_valid.shape}\")\nprint(f\"Test: {X_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:41:10.807466Z","iopub.execute_input":"2024-04-18T12:41:10.811910Z","iopub.status.idle":"2024-04-18T12:41:10.832437Z","shell.execute_reply.started":"2024-04-18T12:41:10.811714Z","shell.execute_reply":"2024-04-18T12:41:10.831104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**lightgbm**","metadata":{}},{"cell_type":"code","source":"lgb_train = lgb.Dataset(X_train, label=y_train)\nlgb_valid = lgb.Dataset(X_valid, label=y_valid, reference=lgb_train)\nparams = {\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"max_depth\": 3,\n    \"num_leaves\": 31,\n    \"learning_rate\": 0.05,\n    \"feature_fraction\": 0.9,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 5,\n    \"n_estimators\": 1000,\n    \"verbose\": -1,\n}\ngbm = lgb.train(\n    params,\n    lgb_train,\n    valid_sets=lgb_valid,\n    callbacks=[lgb.log_evaluation(50), lgb.early_stopping(10)]\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:41:10.834271Z","iopub.execute_input":"2024-04-18T12:41:10.834768Z","iopub.status.idle":"2024-04-18T12:42:41.952693Z","shell.execute_reply.started":"2024-04-18T12:41:10.834728Z","shell.execute_reply":"2024-04-18T12:42:41.951522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"evaluation auc","metadata":{}},{"cell_type":"code","source":"for base, X in [(base_train, X_train), (base_valid, X_valid), (base_test, X_test)]:\n    y_pred = gbm.predict(X, num_iteration=gbm.best_iteration)\n    base[\"score\"] = y_pred\nprint(f'The AUC score on the train set is: {roc_auc_score(base_train[\"target\"], base_train[\"score\"])}') \nprint(f'The AUC score on the valid set is: {roc_auc_score(base_valid[\"target\"], base_valid[\"score\"])}') \nprint(f'The AUC score on the test set is: {roc_auc_score(base_test[\"target\"], base_test[\"score\"])}')  ","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:42:41.954198Z","iopub.execute_input":"2024-04-18T12:42:41.954521Z","iopub.status.idle":"2024-04-18T12:43:02.867029Z","shell.execute_reply.started":"2024-04-18T12:42:41.954494Z","shell.execute_reply":"2024-04-18T12:43:02.865650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gini_stability(base, w_fallingrate=88.0, w_resstd=-0.5):\n    gini_in_time = base.loc[:, [\"WEEK_NUM\", \"target\", \"score\"]]\\\n        .sort_values(\"WEEK_NUM\")\\\n        .groupby(\"WEEK_NUM\")[[\"target\", \"score\"]]\\\n        .apply(lambda x: 2*roc_auc_score(x[\"target\"], x[\"score\"])-1).tolist()\n    \n    x = np.arange(len(gini_in_time))\n    y = gini_in_time\n    a, b = np.polyfit(x, y, 1)\n    y_hat = a*x + b\n    residuals = y - y_hat\n    res_std = np.std(residuals)\n    avg_gini = np.mean(gini_in_time)\n    return avg_gini + w_fallingrate * min(0, a) + w_resstd * res_std\nstability_score_train = gini_stability(base_train)\nstability_score_valid = gini_stability(base_valid)\nstability_score_test = gini_stability(base_test)\nprint(f'The stability score on the train set is: {stability_score_train}') \nprint(f'The stability score on the valid set is: {stability_score_valid}') \nprint(f'The stability score on the test set is: {stability_score_test}')  ","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:43:02.874218Z","iopub.execute_input":"2024-04-18T12:43:02.874597Z","iopub.status.idle":"2024-04-18T12:43:04.019514Z","shell.execute_reply.started":"2024-04-18T12:43:02.874569Z","shell.execute_reply":"2024-04-18T12:43:04.018279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**submission** ","metadata":{}},{"cell_type":"code","source":"X_submission = data_test[cols_pred].to_pandas()\nX_submission = convert_strings(X_submission)\ncategorical_cols = X_train.select_dtypes(include=['category']).columns\nfor col in categorical_cols:\n    train_categories = set(X_train[col].cat.categories)\n    submission_categories = set(X_submission[col].cat.categories)\n    new_categories = submission_categories - train_categories\n    X_submission.loc[X_submission[col].isin(new_categories), col] = \"Unknown\"\n    new_dtype = pd.CategoricalDtype(categories=train_categories, ordered=True)\n    X_train[col] = X_train[col].astype(new_dtype)\n    X_submission[col] = X_submission[col].astype(new_dtype)\ny_submission_pred = gbm.predict(X_submission, num_iteration=gbm.best_iteration)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:43:04.021161Z","iopub.execute_input":"2024-04-18T12:43:04.021504Z","iopub.status.idle":"2024-04-18T12:43:04.140439Z","shell.execute_reply.started":"2024-04-18T12:43:04.021475Z","shell.execute_reply":"2024-04-18T12:43:04.139474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"case_id\": data_test[\"case_id\"].to_numpy(),\n    \"score\": y_submission_pred\n}).set_index('case_id')\nsubmission.to_csv(\"./submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T12:43:58.541286Z","iopub.execute_input":"2024-04-18T12:43:58.541736Z","iopub.status.idle":"2024-04-18T12:43:58.560147Z","shell.execute_reply.started":"2024-04-18T12:43:58.541690Z","shell.execute_reply":"2024-04-18T12:43:58.559043Z"},"trusted":true},"execution_count":null,"outputs":[]}]}